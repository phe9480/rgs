% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wlr.power.maxcombo.R
\name{wlr.power.maxcombo}
\alias{wlr.power.maxcombo}
\title{Power Calculation for Group Sequential Design Using A Max-combo Test}
\usage{
wlr.power.maxcombo(
  n = 600,
  r = 1,
  DCO = c(24, 36),
  alpha = c(0.02, 0.03)/2,
  h0 = function(t) {     log(2)/12 },
  S0 = function(t) {     exp(-log(2)/12 * t) },
  h1 = function(t) {     log(2)/12 * 0.7 },
  S1 = function(t) {     exp(-log(2)/12 * 0.7 * t) },
  f.ws = list(IA1 = list(function(s) {     1 }), FA = list(function(s) {     1 },
    function(s) {     s * (1 - s) })),
  cuts = NULL,
  Lambda = function(t) {     (t/18)^1.5 * as.numeric(t <= 18) + as.numeric(t > 18) },
  G0 = function(t) {     0 },
  G1 = function(t) {     0 },
  mu.method = "Schoenfeld",
  cov.method = "H0"
)
}
\arguments{
\item{n}{Total sample size for two arms.}

\item{r}{Randomization ratio of experimental arm : control arm as r:1.
When r = 1, it is equal allocation. Default r = 1.}

\item{DCO}{Analysis time, calculated from first subject in.}

\item{alpha}{Allocated one-sided alpha levels. sum(alpha) is the total type I error.
If alpha spending function a(t) is used for information time c(t1, ..., tK),
then alpha1 = a(t1), alpha2 = a(t2)-a(t1), ..., alphaK = a(tK)-a(t_{K-1}),
and the total alpha for all analyses is a(tK).}

\item{h0}{Hazard function of control arm. h0(t) = log(2)/m0 means T~exponential distribution with median m0.}

\item{S0}{Survival function of control arm. In general, S0(t) = exp(- integral of h0(u) for u from 0 to t).
but providing S0(t) can improves computational efficiency and
usually the survival function is known in study design. The density function f0(t) = h0(t) * S0(t).}

\item{h1}{Hazard function of experimental arm. h1(t) = log(2)/m1 means T~exponential distribution with median m0.}

\item{S1}{Survival function of experimental arm. In general, S1(t) = exp(- integral of h1(u) for u from 0 to t).
but providing S1(t) can improves computational efficiency and
usually the survival function is known in study design. The density function f1(t) = h1(t) * S1(t).}

\item{f.ws}{Self-defined weight function of survival rate, eg, f.ws = function(s){1/max(s, 0.25)}
When f.ws is specified, sFH parameter will be ignored.}

\item{cuts}{A vector of cut points to define piecewise distributions.
If cuts is not specified or incorrectly specified, it might occasionally have numerical integration issue.}

\item{Lambda}{Cumulative distribution function of enrollment.}

\item{G0}{Cumulative distribution function of drop-off for control arm, eg, G.ltfu=function(t){1-exp(-0.03/12*t)}
is the distribution function for 3 percent drop-off in 12 months of followup.}

\item{G1}{Cumulative distribution function of drop-off for experimental arm, eg, G.ltfu=function(t){1-exp(-0.03/12*t)}
is the distribution function for 3 percent drop-off in 12 months of followup.}

\item{mu.method}{Method for mean of weighted logrank test Z statistic.
"Schoenfeld" or "H1"}

\item{cov.method}{Method for covariance matrix calculation in power calculation:
"H0", "H1", "H1.LA" for null hypothesis H0, H1, H1 under local alternative}

\item{b}{Rejection boundary in normalized Z. If b is NULL, then the boundaries
will be calculated based on alpha at each analysis time T. Default b = NULL.
If b is provided, then alpha is ignored. Default NULL.}

\item{rho}{Parameter for Fleming-Harrington (rho, gamma) weighted log-rank test.}

\item{gamma}{Parameter for Fleming-Harrington (rho, gamma) weighted log-rank test.
For log-rank test, set rho = gamma = 0.}

\item{tau}{Cut point for stabilized FH test, sFH(rho, gamma, tau); with weight
function defined as w(t) = s_tilda^rho*(1-s_tilda)^gamma, where
s_tilda = max(s(t), s.tau) or max(s(t), s(tau)) if s.tau = NULL
tau = Inf reduces to regular Fleming-Harrington test(rho, gamma)}

\item{s.tau}{Survival rate cut S(tau) at t = tau1; default 0.5, ie. cut at median.
s.tau = 0 reduces to regular Fleming-Harrington test(rho, gamma)}
}
\value{
An object with dataframes below.
\itemize{
\item  n:      Total number of subjects for two arms
\item  DCO:    Expected analysis time
\item  targetEvents: Expected number of events
\item  power:  Power of the max-combo test at each analysis
\item  overall.power Overall power of the study
\item  incr.power Incremental power for each analysis.
The sum of all incremental powers is the overall power.
\item  medians: Median of each treatment group
\item  b:    Expected rejection boundary in z value
\item  Expected_HR: Expected HR
}
Omega0: Covariance matrix under H0;
Omega1: Covariance matrix for power calculation request in cov.method.
}
\description{
Power Calculation for Group Sequential Design Using A Max-combo Test
}
\examples{
#Distributions for both arms
m0 = 12; #median OS for control arm
lambda0 = log(2) / m0
h0 = function(t){lambda0}; 
S0 = function(t){exp(-lambda0 * t)}
HRd = 0.60 #hazard ratio after delay

h.D3=function(t){lambda0*as.numeric(t<3)+HRd*lambda0*as.numeric(t>=3)}
c3 = exp(-3*lambda0*(1-HRd)); 
S.D3 = function(t){S0(t)*as.numeric(t<3)+c3*exp(-HRd*lambda0*t)*as.numeric(t>=3)}

#Define weight functions for weighted log-rank tests
lr = function(s){1}
fh01 = function(s){(1-s)}
fh11 = function(s){s*(1-s)}

#Enrollment
Lambda = function(t){(t/18)^1.5*as.numeric(t <= 18) + as.numeric(t > 18)};
G0 = function(t){0}; G1 = function(t){0}; 

#Schoenfeld method with power based on covariance matrix under H0
wlr.power.maxcombo(DCO = c(24, 36),  
  alpha=c(0.01, 0.04)/2, 
  r = 1, n = 500, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, 
  f.ws = list(IA1 = list(lr), FA=list(fh01)), 
  Lambda=Lambda, G0=G0, G1=G1,
  mu.method = "Schoenfeld", cov.method = "H0")
  
#Schoenfeld method with power based on covariance matrix under H1
wlr.power.maxcombo(DCO = c(24, 36),  
  alpha=c(0.01, 0.04)/2, 
  r = 1, n = 500, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, 
  f.ws = list(IA1 = list(lr), FA=list(fh01)), 
  Lambda=Lambda, G0=G0, G1=G1,
  mu.method = "Schoenfeld", cov.method = "H1")
  
#Schoenfeld method with power based on covariance matrix under H1 in Local Alternative (simplified)
wlr.power.maxcombo(DCO = c(24, 36),  
  alpha=c(0.01, 0.04)/2, 
  r = 1, n = 500, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, 
  f.ws = list(IA1 = list(lr), FA=list(fh01)), 
  Lambda=Lambda, G0=G0, G1=G1,
  mu.method = "Schoenfeld", cov.method = "H1.LA")   
     
#Mean(Z) under H1 with power based on covariance matrix under H0
wlr.power.maxcombo(DCO = c(24, 36),  
  alpha=c(0.01, 0.04)/2, 
  r = 1, n = 500, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, 
  f.ws = list(IA1 = list(lr), FA=list(fh01)), 
  Lambda=Lambda, G0=G0, G1=G1,
  mu.method = "H1", cov.method = "H0")
  
#Mean(Z) under H1 with power based on covariance matrix under H1
wlr.power.maxcombo(DCO = c(24, 36),  
  alpha=c(0.01, 0.04)/2, 
  r = 1, n = 500, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, 
  f.ws = list(IA1 = list(lr), FA=list(fh01)), 
  Lambda=Lambda, G0=G0, G1=G1,
  mu.method = "H1", cov.method = "H1")
  
#Mean(Z) under H1 with power based on covariance matrix under H1 in Local Alternative (simplified)
wlr.power.maxcombo(DCO = c(24, 36),  
  alpha=c(0.01, 0.04)/2, 
  r = 1, n = 500, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, 
  f.ws = list(IA1 = list(lr), FA=list(fh01)), 
  Lambda=Lambda, G0=G0, G1=G1,
  mu.method = "H1", cov.method = "H1.LA")   

#max-combo(logrank, FH11) at FA   
#Mean(Z) under H1 with power based on covariance matrix under H1 in Local Alternative (simplified)
wlr.power.maxcombo(DCO = c(24, 36),  
  alpha=c(0.01, 0.04)/2, 
  r = 1, n = 500, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, 
  f.ws = list(IA1 = list(lr), FA=list(lr, fh11)), 
  Lambda=Lambda, G0=G0, G1=G1,
  mu.method = "H1", cov.method = "H1.LA")   
  
#max-combo(logrank, FH11) at FA   
#Mean(Z) under H1 with power based on covariance matrix under H1
wlr.power.maxcombo(DCO = c(24, 36),  
  alpha=c(0.01, 0.04)/2, 
  r = 1, n = 500, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, 
  f.ws = list(IA1 = list(lr), FA=list(lr, fh11)), 
  Lambda=Lambda, G0=G0, G1=G1,
  mu.method = "H1", cov.method = "H1")   
        
}
